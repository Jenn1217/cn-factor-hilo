{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54941b77",
   "metadata": {},
   "source": [
    "选取一个因子新建小表，表中只有四个因素\n",
    "\n",
    "sub_table = predictor[['STKCD','TRDMNT',sort_factor,'ret']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa16dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import func\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "chunk_size = 100000\n",
    "op_path = 'output'\n",
    "ngroup = 10\n",
    "\n",
    "def get_stat(ret_df, max_lag: int = None):\n",
    "\n",
    "    inner_df = ret_df.copy()\n",
    "\n",
    "    ret_mean = inner_df.mean() * 100\n",
    "\n",
    "    if max_lag == None:\n",
    "        ret_t = stats.ttest_1samp(inner_df, 0)[0]\n",
    "        ret_p = stats.ttest_1samp(inner_df, 0)[1]\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    else:\n",
    "        assert type(max_lag) == int, \"input an integer max_lag\"\n",
    "        ret_t = []\n",
    "        ret_p = []\n",
    "        for col in inner_df.columns:\n",
    "            reg = smf.ols(f\"{col} ~ 1\", data=inner_df).fit(\n",
    "                cov_type='HAC', cov_kwds={'maxlags': max_lag})\n",
    "            t_v = reg.tvalues['Intercept']\n",
    "            p_v = reg.pvalues['Intercept']\n",
    "            ret_t.append(t_v)\n",
    "            ret_p.append(p_v)\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    \n",
    "    ret_mean.name = 'mean'\n",
    "    ret_t.name = 't'\n",
    "    ret_p.name = 'p'\n",
    "    \n",
    "    stats_data = pd.DataFrame([ret_mean, ret_t, ret_p])\n",
    "    return stats_data\n",
    "\n",
    "\n",
    "def read_csv(csv_path, chunk_size=100000):\n",
    "    try:\n",
    "        # 方法 A: 标准读取 (默认逗号分隔)\n",
    "        #df_csv = pd.read_csv('CHN24/all_predictors.csv')\n",
    "        # 强制将 'STKCD' 列读取为字符串，保留 000002\n",
    "        df_csv = pd.read_csv(csv_path, dtype={'STKCD': str})\n",
    "\n",
    "        # 检查一下\n",
    "        print(df_csv['STKCD'].head())\n",
    "    except UnicodeDecodeError:\n",
    "        # 方法 B: 如果是中文 CSV (特别是 Excel 导出的)，通常需要 gbk 或 gb18030 编码\n",
    "        print(\"默认编码失败，尝试 GBK...\")\n",
    "        df_csv = pd.read_csv('CHN24/all_predictors.csv', encoding='gbk')\n",
    "\n",
    "    # 预览 CSV 数据\n",
    "    print(\"\\nCSV 数据预览：\")\n",
    "    print(df_csv.head())\n",
    "    return df_csv\n",
    "\n",
    "def match_df_flex(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    *,\n",
    "    left_on: list[str],\n",
    "    right_on: list[str],\n",
    "    how: str = \"left\",\n",
    "    validate: str = \"many_to_one\"\n",
    "):\n",
    "    if len(left_on) != len(right_on):\n",
    "        raise ValueError(\"left_on 和 right_on 长度必须一致\")\n",
    "\n",
    "    for col in left_on:\n",
    "        if col not in df1.columns:\n",
    "            raise ValueError(f\"[df1] 缺少列: {col}\")\n",
    "\n",
    "    for col in right_on:\n",
    "        if col not in df2.columns:\n",
    "            raise ValueError(f\"[df2] 缺少列: {col}\")\n",
    "\n",
    "    # df2 去重保护\n",
    "    if df2.duplicated(subset=right_on).any():\n",
    "        raise ValueError(\"df2 在 right_on 上存在重复键\")\n",
    "\n",
    "    df_merged = pd.merge(\n",
    "        df1,\n",
    "        df2,\n",
    "        how=how,\n",
    "        left_on=left_on,\n",
    "        right_on=right_on,\n",
    "        validate=validate\n",
    "    )\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def cleanBlank(df, sort1, sort2):\n",
    "    # 1️⃣ 先保存一份 df\n",
    "    df = df.copy()\n",
    "\n",
    "    # 2️⃣ 排序\n",
    "    df = df.sort_values(by=[sort1, sort2])\n",
    "\n",
    "    # 3️⃣ 记录删除前行数\n",
    "    n_before = len(df)\n",
    "\n",
    "    # 4️⃣ 删除含 NaN 的行（只要有一个 NaN 就删）\n",
    "    df = df.dropna(axis=0)\n",
    "\n",
    "    # 5️⃣ 记录删除后行数\n",
    "    n_after = len(df)\n",
    "\n",
    "    # 6️⃣ 打印删除信息\n",
    "    print(f\"firstSort: 删除了 {n_before - n_after} 行（{n_before} → {n_after}）\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- 工具：任意格式 -> YYYYMM(Int64) ----------\n",
    "def to_yyyymm(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.strip()\n",
    "\n",
    "    # 情况A：已经是 6 位 YYYYMM\n",
    "    mask6 = s.str.fullmatch(r\"\\d{6}\", na=False)\n",
    "\n",
    "    out = pd.Series([pd.NA] * len(s), index=s.index, dtype=\"Int64\")\n",
    "\n",
    "    # 6位直接转\n",
    "    out.loc[mask6] = s.loc[mask6].astype(\"Int64\")\n",
    "\n",
    "    # 情况B：YYYY-MM / YYYY-MM-DD / datetime 等\n",
    "    dt = pd.to_datetime(s.loc[~mask6], errors=\"coerce\")\n",
    "    out.loc[~mask6] = (dt.dt.year * 100 + dt.dt.month).astype(\"Int64\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------- 读取数据 ----------\n",
    "df_csv = read_csv('CHN24/all_predictors.csv')\n",
    "df_csv = df_csv.drop(columns=['Unnamed: 0'], errors='ignore')  # 防止垃圾索引列混进来\n",
    "\n",
    "# ---------- 统一 TRDMNT 为 YYYYMM ----------\n",
    "df_csv[\"TRDMNT\"] = to_yyyymm(df_csv[\"date\"])\n",
    "\n",
    "print(\"TRDMNT dtype:\", df_csv[\"TRDMNT\"].dtype)\n",
    "print(\"TRDMNT NA:\", df_csv[\"TRDMNT\"].isna().sum())\n",
    "print(df_csv[[\"TRDMNT\"]].head())\n",
    "\n",
    "# ---------- 定义起止时间（YYYYMM int） ----------\n",
    "start_month = 200001\n",
    "end_month   = 202412\n",
    "# 日期筛选\n",
    "df_csv_filtered = df_csv.loc[\n",
    "    (df_csv[\"TRDMNT\"] >= start_month) & (df_csv[\"TRDMNT\"] <= end_month)\n",
    "].copy()\n",
    "\n",
    "print(\"before/after:\", len(df_csv), len(df_csv_filtered))\n",
    "print(\"min/max after:\", df_csv_filtered[\"TRDMNT\"].min(), df_csv_filtered[\"TRDMNT\"].max())\n",
    "\n",
    "# ---------- 合并月度 return ----------\n",
    "df_monret = func.read_csv('CHN24/monret.csv')\n",
    "df_monret = df_monret.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "# 统一 monret 的 TRDMNT 为 YYYYMM\n",
    "df_monret[\"TRDMNT\"] = to_yyyymm(df_monret[\"TRDMNT\"])\n",
    "\n",
    "print(\"monret TRDMNT dtype:\", df_monret[\"TRDMNT\"].dtype)\n",
    "print(\"monret TRDMNT NA:\", df_monret[\"TRDMNT\"].isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e353a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge\n",
    "df_merged = match_df_flex(\n",
    "    df_csv_filtered, df_monret,\n",
    "    left_on=['STKCD', 'TRDMNT'],\n",
    "    right_on=['STKCD', 'TRDMNT'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "# 删除列（加 errors='ignore' 防止列不存在直接炸）\n",
    "cols_to_drop = [\n",
    "    'OPNDT', 'MOPNPRC', 'CLSDT', 'MCLSPRC', 'MNSHRTRD', 'MNVALTRD',\n",
    "    'MSMVOSD', 'MSMVTTL', 'NDAYTRD', 'CAPCHGDT',\n",
    "    'AHSHRTRD_M', 'AHVALTRD_M'\n",
    "]\n",
    "\n",
    "df_merged_drop = df_merged.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "print(df_merged_drop.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91364f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 导出：关键！不要写 index，否则下次读又出 Unnamed: 0\n",
    "os.makedirs(op_path, exist_ok=True)\n",
    "df_merged_drop.to_csv(os.path.join(op_path, \"df_merged_all.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac814be7",
   "metadata": {},
   "source": [
    "导入已经合并后的表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9519c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    000002\n",
      "1    000002\n",
      "2    000002\n",
      "3    000002\n",
      "4    000002\n",
      "Name: STKCD, dtype: str\n",
      "\n",
      "CSV 数据预览：\n",
      "    STKCD        date     mom6m    mom12m    mom36m     mom1m     chmom  \\\n",
      "0  000002  2000-01-31 -0.041354  0.182541 -0.084426  0.141829 -0.138944   \n",
      "1  000002  2000-02-29 -0.136440  0.459048  0.208242 -0.122412 -0.931725   \n",
      "2  000002  2000-03-31 -0.163550  0.376680  0.052413  0.161126 -0.674637   \n",
      "3  000002  2000-04-30 -0.009539  0.633882  0.029622  0.405687 -0.257339   \n",
      "4  000002  2000-05-31  0.499882  1.249856 -0.181686 -0.144302 -0.216577   \n",
      "\n",
      "        turn  IPO    indmom  ...  gAd        Ol  AnA  ReA  Tan  INA  TRDMNT  \\\n",
      "0   2.067810  0.0  0.168533  ...  NaN  0.475384  NaN  NaN  NaN  0.0  200001   \n",
      "1   2.328343  0.0  0.277902  ...  NaN  0.475384  NaN  NaN  NaN  0.0  200002   \n",
      "2   3.386074  0.0  0.222441  ...  NaN  0.475384  NaN  NaN  NaN  0.0  200003   \n",
      "3   6.743252  0.0  0.489288  ...  NaN  0.475384  NaN  NaN  NaN  0.0  200004   \n",
      "4  10.224872  0.0  0.546886  ...  NaN  0.475384  NaN  NaN  NaN  0.0  200005   \n",
      "\n",
      "     MRETWD    MRETND  MARKETTYPE  \n",
      "0  0.161126  0.138389         4.0  \n",
      "1  0.405687  0.405687         4.0  \n",
      "2 -0.144302 -0.144302         4.0  \n",
      "3 -0.016548 -0.016548         4.0  \n",
      "4 -0.047276 -0.047276         4.0  \n",
      "\n",
      "[5 rows x 118 columns]\n"
     ]
    }
   ],
   "source": [
    "df_csv_all=read_csv('output/df_merged_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305b534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STKCD', 'date', 'mom6m', 'mom12m', 'mom36m', 'mom1m', 'chmom', 'turn', 'IPO', 'indmom', 'maxret', 'retvol', 'std_dolvol', 'std_turn', 'ill', 'zerotrade', 'beta', 'betasq', 'pricedelay', 'idiovol', 'prc', 'size', 'volt', 'B_Mkt', 'B_Mktsq', 'B_Dim', 'B_Dn', 'B_FF', 'B_HS', 'B_LSY', 'ACC', 'PACC', 'age', 'ATO', 'BM', 'CAPXG', 'CFD', 'CFOA', 'CFP', 'CP', 'CR', 'CRG', 'CTA', 'CTO', 'dBe', 'DP', 'EBIT', 'EP', 'EY', 'GM', 'GP', 'IVC', 'IVG', 'IA', 'am', 'LG', 'DER', 'DLME', 'NOA', 'NPOP', 'dPIA', 'PY', 'QR', 'QRG', 'RNA', 'ROA', 'ROE', 'ROIC', 'SC', 'SI', 'SMI', 'SP', 'SG', 'TG', 'TBI', 'Z', 'CHTX', 'CINVEST', 'realestate', 'salerev', 'IC', 'DA', 'DPR', 'TOR', 'EPS', 'CEPS', 'NCF', 'GS', 'ROO', 'RFI', 'TA', 'AD', 'FM', 'FOE', 'IP', 'FVAD', 'NAPS', 'RSGL', 'TMT', 'CAC', 'IBV', 'RDS', 'RDM', 'RCA', 'VAHU', 'Hn', 'LFE', 'Adm', 'gAd', 'Ol', 'AnA', 'ReA', 'Tan', 'INA', 'TRDMNT', 'MRETWD', 'MRETND', 'MARKETTYPE']\n"
     ]
    }
   ],
   "source": [
    "print(df_csv_all.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f892149",
   "metadata": {},
   "source": [
    "## 因子列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af9ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因子列数量: 112\n",
      "前10个因子列: ['mom6m', 'mom12m', 'mom36m', 'mom1m', 'chmom', 'turn', 'IPO', 'indmom', 'maxret', 'retvol']\n"
     ]
    }
   ],
   "source": [
    "non_factor_cols = [\n",
    "    'Unnamed: 0',   # 索引垃圾列\n",
    "    'STKCD',        # 股票代码（实体标识）\n",
    "    'date',         # 原始日期\n",
    "    'TRDMNT',       # 月份（面板时间索引）\n",
    "    'MRETWD',       # 含分红收益（因变量）\n",
    "    'MRETND',       # 不含分红收益（因变量）\n",
    "    'MARKETTYPE'    # 市场分类标签\n",
    "]\n",
    "\n",
    "# 只保留真正的因子列\n",
    "factor_cols = [\n",
    "    c for c in df_csv_all.columns\n",
    "    if c not in non_factor_cols\n",
    "]\n",
    "\n",
    "print(\"因子列数量:\", len(factor_cols))\n",
    "print(\"前10个因子列:\", factor_cols[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eefcb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STKCD', 'date', 'mom6m', 'mom12m', 'mom36m', 'mom1m', 'chmom', 'turn', 'IPO', 'indmom', 'maxret', 'retvol', 'std_dolvol', 'std_turn', 'ill', 'zerotrade', 'beta', 'betasq', 'pricedelay', 'idiovol', 'prc', 'size', 'volt', 'B_Mkt', 'B_Mktsq', 'B_Dim', 'B_Dn', 'B_FF', 'B_HS', 'B_LSY', 'ACC', 'PACC', 'age', 'ATO', 'BM', 'CAPXG', 'CFD', 'CFOA', 'CFP', 'CP', 'CR', 'CRG', 'CTA', 'CTO', 'dBe', 'DP', 'EBIT', 'EP', 'EY', 'GM', 'GP', 'IVC', 'IVG', 'IA', 'am', 'LG', 'DER', 'DLME', 'NOA', 'NPOP', 'dPIA', 'PY', 'QR', 'QRG', 'RNA', 'ROA', 'ROE', 'ROIC', 'SC', 'SI', 'SMI', 'SP', 'SG', 'TG', 'TBI', 'Z', 'CHTX', 'CINVEST', 'realestate', 'salerev', 'IC', 'DA', 'DPR', 'TOR', 'EPS', 'CEPS', 'NCF', 'GS', 'ROO', 'RFI', 'TA', 'AD', 'FM', 'FOE', 'IP', 'FVAD', 'NAPS', 'RSGL', 'TMT', 'CAC', 'IBV', 'RDS', 'RDM', 'RCA', 'VAHU', 'Hn', 'LFE', 'Adm', 'gAd', 'Ol', 'AnA', 'ReA', 'Tan', 'INA', 'TRDMNT', 'RET', 'MRETND', 'MARKETTYPE']\n"
     ]
    }
   ],
   "source": [
    "# 2️⃣ 重命名 'MRETWD' 为 'RET'\n",
    "df_csv_all = df_csv_all.rename(columns={'MRETWD': 'RET'})\n",
    "\n",
    "# 3️⃣ 查看结果\n",
    "print(df_csv_all.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0bc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_filtered=df_csv_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4f3a2",
   "metadata": {},
   "source": [
    "# 选取小表\n",
    "任意选取了一个指标,如“RDM”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278bf430",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_factor = factor_cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f70fea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_table = df_csv_filtered[['STKCD','TRDMNT',sort_factor,'RET','size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2465bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    STKCD  TRDMNT     mom6m       RET        size\n",
      "0  000002  200001 -0.041354  0.161126  3054483.23\n",
      "1  000002  200002 -0.136440  0.405687  4206410.30\n",
      "2  000002  200003 -0.163550 -0.144302  5912897.14\n",
      "3  000002  200004 -0.009539 -0.016548  5059653.72\n",
      "4  000002  200005  0.499882 -0.047276  4975924.22\n"
     ]
    }
   ],
   "source": [
    "print(sub_table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19212e62",
   "metadata": {},
   "source": [
    "## 清理空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ca5382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstSort: 删除了 23548 行（698913 → 675365）\n",
      "      STKCD  TRDMNT     mom6m       RET        size\n",
      "0    000002  200001 -0.041354  0.161126  3054483.23\n",
      "294  000003  200001  0.201855  0.053016  1048897.09\n",
      "318  000004  200001  0.251481  0.573443   354501.00\n",
      "609  000005  200001 -0.047620  0.365894  1483602.27\n",
      "885  000006  200001 -0.107001  0.161734  1492854.59\n"
     ]
    }
   ],
   "source": [
    "df_clean=cleanBlank(sub_table, 'TRDMNT','STKCD')\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9f64f",
   "metadata": {},
   "source": [
    "# 运行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "375f2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "#                   第一步、分组\n",
    "#========================================================\n",
    "\n",
    "def GroupN(in_df, sort_var, vars, n_group=10):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[f\"{vars}_g{n_group}\"] = out_df.groupby(sort_var)[vars].transform(\n",
    "        lambda x: pd.qcut(x, q=n_group, labels=[i for i in range(1, n_group+1)]))\n",
    "    out_df[f\"{vars}_g{n_group}\"] = out_df[f\"{vars}_g{n_group}\"] .astype(int)\n",
    "    return out_df\n",
    "\n",
    "sub_table_groupped = GroupN(df_clean, 'TRDMNT', sort_factor , n_group = ngroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "151d6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "#                   第二步、缩尾处理\n",
    "#          对除了keep_cols以外的所有因子进行缩尾处理\n",
    "#========================================================\n",
    "\n",
    "class Winsorize:\n",
    "    def __init__(self, in_df, sort_var, vars, perc=1, trim=0) -> None:\n",
    "        self.in_df = in_df\n",
    "        self.sort_var = sort_var\n",
    "        self.vars = vars\n",
    "        self.perc = perc\n",
    "        self.trim = trim\n",
    "\n",
    "    def func_trim(self, in_ser, perc):\n",
    "        perc_upper = (100 - perc) / 100\n",
    "        perc_lower = perc / 100\n",
    "\n",
    "        qt_lower, qt_upper = in_ser.quantile([perc_lower, perc_upper])\n",
    "        in_ser[in_ser > qt_upper] = np.nan\n",
    "        in_ser[in_ser < qt_lower] = np.nan\n",
    "        return in_ser\n",
    "\n",
    "    def func_winsor(self, in_ser, perc):\n",
    "        perc_upper = (100 - perc) / 100\n",
    "        perc_lower = perc / 100\n",
    "        qt_lower, qt_upper = in_ser.quantile([perc_lower, perc_upper])\n",
    "\n",
    "        in_ser[in_ser > qt_upper] = qt_upper\n",
    "        in_ser[in_ser < qt_lower] = qt_lower\n",
    "        return in_ser\n",
    "\n",
    "    def get(self, ):\n",
    "        out_df = self.in_df.copy()\n",
    "        if self.trim == 1:\n",
    "            proc_method = self.func_trim\n",
    "        if self.trim == 0:\n",
    "            proc_method = self.func_winsor\n",
    "\n",
    "        out_df[f\"{self.vars}\"] = out_df.groupby(\n",
    "            self.sort_var)[self.vars].transform(lambda x: proc_method(x, 1))\n",
    "\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed00c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winsorize\n",
    "#先对size进行缩尾处理\n",
    "winsor = Winsorize(sub_table_groupped, \"TRDMNT\",'size')\n",
    "sub_table_groupped = winsor.get()\n",
    "# 第二次缩尾：按（月 × 因子组）对 size 缩尾\n",
    "winsor = Winsorize(sub_table_groupped, [\"TRDMNT\",f\"{sort_factor}_g{ngroup}\" ],'size')\n",
    "sub_table_groupped = winsor.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0500a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#========================================================\n",
    "#                   第三步、计算EW VW\n",
    "#           EW=同一个月 (TRDMNT)\n",
    "#           同一个因子分组（比如 AM_g10 的第 3 组）\n",
    "#           把这一组里所有股票的收益率 ret 简单平均。\n",
    "#           VW=同一个月\n",
    "#           同一个因子组\n",
    "#           用上一期市值 size 当权重，对收益率加权平均\n",
    "#\n",
    "#       在这里的收益率指的是RET [考虑现金红利再投资的月个股回报率]\n",
    "#       从这里开始就只有一个了，上面都是对全部的因子进行循环处理\n",
    "#======================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17f56a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      STKCD  TRDMNT     mom6m       RET        size  mom6m_g10\n",
      "0    000002  200001 -0.041354  0.161126  3054483.23          1\n",
      "294  000003  200001  0.201855  0.053016  1048897.09          6\n",
      "318  000004  200001  0.251481  0.573443   354501.00          7\n",
      "609  000005  200001 -0.047620  0.365894  1483602.27          1\n",
      "885  000006  200001 -0.107001  0.161734  1492854.59          1\n"
     ]
    }
   ],
   "source": [
    "print(sub_table_groupped.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e574214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def get_stat(ret_df, max_lag: int = None):\n",
    "\n",
    "    inner_df = ret_df.copy()\n",
    "\n",
    "    ret_mean = inner_df.mean() * 100\n",
    "\n",
    "    if max_lag == None:\n",
    "        ret_t = stats.ttest_1samp(inner_df, 0)[0]\n",
    "        ret_p = stats.ttest_1samp(inner_df, 0)[1]\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    else:\n",
    "        assert type(max_lag) == int, \"input an integer max_lag\"\n",
    "        ret_t = []\n",
    "        ret_p = []\n",
    "        for col in inner_df.columns:\n",
    "            reg = smf.ols(f\"{col} ~ 1\", data=inner_df).fit(\n",
    "                cov_type='HAC', cov_kwds={'maxlags': max_lag})\n",
    "            t_v = reg.tvalues['Intercept']\n",
    "            p_v = reg.pvalues['Intercept']\n",
    "            ret_t.append(t_v)\n",
    "            ret_p.append(p_v)\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    \n",
    "    ret_mean.name = 'mean'\n",
    "    ret_t.name = 't'\n",
    "    ret_p.name = 'p'\n",
    "    \n",
    "    stats_data = pd.DataFrame([ret_mean, ret_t, ret_p])\n",
    "    return stats_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a6be65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      STKCD  TRDMNT     mom6m       RET        size  mom6m_g10\n",
      "0    000002  200001 -0.041354  0.161126  3054483.23          1\n",
      "294  000003  200001  0.201855  0.053016  1048897.09          6\n",
      "318  000004  200001  0.251481  0.573443   354501.00          7\n",
      "609  000005  200001 -0.047620  0.365894  1483602.27          1\n",
      "885  000006  200001 -0.107001  0.161734  1492854.59          1\n"
     ]
    }
   ],
   "source": [
    "in_ret = sub_table_groupped.copy(deep =True)\n",
    "print(in_ret.head(5))\n",
    "\n",
    "ew_ret = in_ret.groupby(['TRDMNT', f\"{sort_factor}_g{ngroup}\"])['RET'].mean()\n",
    "vw_ret = (\n",
    "    in_ret.groupby(['TRDMNT', f\"{sort_factor}_g{ngroup}\"])\n",
    "          .apply(lambda g: np.average(g['RET'], weights=g['size']))\n",
    ")\n",
    "vw_ret.name = \"Vw_ret\"\n",
    "\n",
    "ew_mean = ew_ret.copy(deep=True)\n",
    "ew_mean.name = 'Ew_ret'\n",
    "\n",
    "vw_mean = vw_ret.copy(deep=True)\n",
    "vw_mean.name = 'Vw_ret'\n",
    "\n",
    "month_count = in_ret.groupby(\n",
    "    ['TRDMNT', f\"{sort_factor}_g{ngroup}\"]\n",
    ")['RET'].count()\n",
    "month_count.name = 'Count'\n",
    "\n",
    "sort_factor_mean = in_ret.groupby(\n",
    "    ['TRDMNT', f\"{sort_factor}_g{ngroup}\"]\n",
    ")[sort_factor].mean()\n",
    "\n",
    "month_result = pd.concat(\n",
    "    [month_count, sort_factor_mean, ew_mean, vw_mean],\n",
    "    axis=1,\n",
    "    ignore_index=False\n",
    ")\n",
    "\n",
    "ew_ret = ew_ret.unstack()\n",
    "vw_ret = vw_ret.unstack()\n",
    "\n",
    "ew_ret.columns = [f\"col_{i+1}\" for i in range(ngroup)]\n",
    "vw_ret.columns = [f\"col_{i+1}\" for i in range(ngroup)]\n",
    "\n",
    "ew_ret['high_low'] = ew_ret[f\"col_{ngroup}\"] - ew_ret[\"col_1\"]\n",
    "vw_ret['high_low'] = vw_ret[f\"col_{ngroup}\"] - vw_ret[\"col_1\"]\n",
    "\n",
    "ew_other = ew_ret.loc[:, ['high_low']]\n",
    "ew_other = ew_other.stack()\n",
    "ew_other.name = 'Ew_ret'\n",
    "\n",
    "vw_other = vw_ret.loc[:, ['high_low']]\n",
    "vw_other = vw_other.stack()\n",
    "vw_other.name = 'Vw_ret'\n",
    "\n",
    "other = pd.concat([ew_other, vw_other], axis=1, ignore_index=False)\n",
    "other = other.reset_index()\n",
    "other = other.rename(columns={'level_1': f\"{sort_factor}_g{ngroup}\"})\n",
    "other = other.set_index(['TRDMNT', f\"{sort_factor}_g{ngroup}\"])\n",
    "\n",
    "month_result = pd.concat([month_result, other], axis=0, ignore_index=False)\n",
    "month_result.sort_index(inplace=True)\n",
    "\n",
    "month_result.to_csv(os.path.join(op_path, f\"{sort_factor}_month_result.csv\"))\n",
    "\n",
    "# 如果 index 是 PeriodIndex，用 to_timestamp\n",
    "if isinstance(ew_ret.index, pd.PeriodIndex):\n",
    "    ew_ret.index = ew_ret.index.to_timestamp(how=\"end\")\n",
    "\n",
    "if isinstance(vw_ret.index, pd.PeriodIndex):\n",
    "    vw_ret.index = vw_ret.index.to_timestamp(how=\"end\")\n",
    "\n",
    "ew_stat = get_stat(ew_ret, max_lag = 3)\n",
    "vw_stat = get_stat(vw_ret, max_lag = 3)\n",
    "\n",
    "ew_stat.to_csv(os.path.join(op_path, f\"{sort_factor}_ew_result.csv\"))\n",
    "vw_stat.to_csv(os.path.join(op_path, f\"{sort_factor}_vw_result.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
