{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e09c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf88f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = 100000\n",
    "op_path = 'output-single'\n",
    "ngroup = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68269a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_stat(ret_df, max_lag: int = None):\n",
    "\n",
    "    inner_df = ret_df.copy()\n",
    "\n",
    "    ret_mean = inner_df.mean() * 100\n",
    "\n",
    "    if max_lag == None:\n",
    "        ret_t = stats.ttest_1samp(inner_df, 0)[0]\n",
    "        ret_p = stats.ttest_1samp(inner_df, 0)[1]\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    else:\n",
    "        assert type(max_lag) == int, \"input an integer max_lag\"\n",
    "        ret_t = []\n",
    "        ret_p = []\n",
    "        for col in inner_df.columns:\n",
    "            reg = smf.ols(f\"{col} ~ 1\", data=inner_df).fit(\n",
    "                cov_type='HAC', cov_kwds={'maxlags': max_lag})\n",
    "            t_v = reg.tvalues['Intercept']\n",
    "            p_v = reg.pvalues['Intercept']\n",
    "            ret_t.append(t_v)\n",
    "            ret_p.append(p_v)\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    \n",
    "    ret_mean.name = 'mean'\n",
    "    ret_t.name = 't'\n",
    "    ret_p.name = 'p'\n",
    "    \n",
    "    stats_data = pd.DataFrame([ret_mean, ret_t, ret_p])\n",
    "    return stats_data\n",
    "\n",
    "\n",
    "def read_csv(csv_path, chunk_size=100000):\n",
    "    try:\n",
    "        # 方法 A: 标准读取 (默认逗号分隔)\n",
    "        #df_csv = pd.read_csv('CHN24/all_predictors.csv')\n",
    "        # 强制将 'STKCD' 列读取为字符串，保留 000002\n",
    "        df_csv = pd.read_csv(csv_path, dtype={'STKCD': str})\n",
    "\n",
    "        # 检查一下\n",
    "        print(df_csv['STKCD'].head())\n",
    "    except UnicodeDecodeError:\n",
    "        # 方法 B: 如果是中文 CSV (特别是 Excel 导出的)，通常需要 gbk 或 gb18030 编码\n",
    "        print(\"默认编码失败，尝试 GBK...\")\n",
    "        df_csv = pd.read_csv('CHN24/all_predictors.csv', encoding='gbk')\n",
    "\n",
    "    # 预览 CSV 数据\n",
    "    print(\"\\nCSV 数据预览：\")\n",
    "    print(df_csv.head())\n",
    "    return df_csv\n",
    "\n",
    "def match_df_flex(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    *,\n",
    "    left_on: list[str],\n",
    "    right_on: list[str],\n",
    "    how: str = \"left\",\n",
    "    validate: str = \"many_to_one\"\n",
    "):\n",
    "    if len(left_on) != len(right_on):\n",
    "        raise ValueError(\"left_on 和 right_on 长度必须一致\")\n",
    "\n",
    "    for col in left_on:\n",
    "        if col not in df1.columns:\n",
    "            raise ValueError(f\"[df1] 缺少列: {col}\")\n",
    "\n",
    "    for col in right_on:\n",
    "        if col not in df2.columns:\n",
    "            raise ValueError(f\"[df2] 缺少列: {col}\")\n",
    "\n",
    "    # df2 去重保护\n",
    "    if df2.duplicated(subset=right_on).any():\n",
    "        raise ValueError(\"df2 在 right_on 上存在重复键\")\n",
    "\n",
    "    df_merged = pd.merge(\n",
    "        df1,\n",
    "        df2,\n",
    "        how=how,\n",
    "        left_on=left_on,\n",
    "        right_on=right_on,\n",
    "        validate=validate\n",
    "    )\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def cleanBlank(df, sort1, sort2):\n",
    "    # 1️⃣ 先保存一份 df\n",
    "    df = df.copy()\n",
    "\n",
    "    # 2️⃣ 排序\n",
    "    df = df.sort_values(by=[sort1, sort2])\n",
    "\n",
    "    # 3️⃣ 记录删除前行数\n",
    "    n_before = len(df)\n",
    "\n",
    "    # 4️⃣ 删除含 NaN 的行（只要有一个 NaN 就删）\n",
    "    df = df.dropna(axis=0)\n",
    "\n",
    "    # 5️⃣ 记录删除后行数\n",
    "    n_after = len(df)\n",
    "\n",
    "    # 6️⃣ 打印删除信息\n",
    "    print(f\"firstSort: 删除了 {n_before - n_after} 行（{n_before} → {n_after}）\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- 工具：任意格式 -> YYYYMM(Int64) ----------\n",
    "def to_yyyymm(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.strip()\n",
    "\n",
    "    # 情况A：已经是 6 位 YYYYMM\n",
    "    mask6 = s.str.fullmatch(r\"\\d{6}\", na=False)\n",
    "\n",
    "    out = pd.Series([pd.NA] * len(s), index=s.index, dtype=\"Int64\")\n",
    "\n",
    "    # 6位直接转\n",
    "    out.loc[mask6] = s.loc[mask6].astype(\"Int64\")\n",
    "\n",
    "    # 情况B：YYYY-MM / YYYY-MM-DD / datetime 等\n",
    "    dt = pd.to_datetime(s.loc[~mask6], errors=\"coerce\")\n",
    "    out.loc[~mask6] = (dt.dt.year * 100 + dt.dt.month).astype(\"Int64\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dac898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv=pd.read_csv('source/ghz_factors.csv', dtype={'STKCD': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_csv.columns.tolist())\n",
    "print(df_csv.head())\n",
    "df_csv['permno'] = pd.to_numeric(df_csv['permno'], errors='coerce').astype('Int64')\n",
    "print(df_csv['permno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- 统一 TRDMNT 为 YYYYMM ----------\n",
    "df_csv[\"TRDMNT\"] = to_yyyymm(df_csv[\"DATE\"])\n",
    "\n",
    "print(\"TRDMNT dtype:\", df_csv[\"TRDMNT\"].dtype)\n",
    "print(\"TRDMNT NA:\", df_csv[\"TRDMNT\"].isna().sum())\n",
    "print(df_csv[[\"TRDMNT\"]].head())\n",
    "\n",
    "# ---------- 定义起止时间（YYYYMM int） ----------\n",
    "start_month = 200001\n",
    "end_month   = 202412\n",
    "# 日期筛选\n",
    "df_csv_filtered = df_csv.loc[\n",
    "    (df_csv[\"TRDMNT\"] >= start_month) & (df_csv[\"TRDMNT\"] <= end_month)\n",
    "].copy()\n",
    "\n",
    "print(\"before/after:\", len(df_csv), len(df_csv_filtered))\n",
    "print(\"min/max after:\", df_csv_filtered[\"TRDMNT\"].min(), df_csv_filtered[\"TRDMNT\"].max())\n",
    "df_csv=df_csv_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(op_path, exist_ok=True)\n",
    "df_csv_filtered.to_csv(os.path.join(op_path, \"us_single.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471dd987",
   "metadata": {},
   "source": [
    "# 因子处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa3a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684b27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_all=pd.read_csv('output-single/us_single.csv', dtype={'STKCD': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aec043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因子列数量: 126\n",
      "前10个因子列: ['sic2', 'spi', 'mve_f', 'bm', 'ep', 'cashpr', 'dy', 'lev', 'sp', 'roic']\n"
     ]
    }
   ],
   "source": [
    "non_factor_cols = [\n",
    "    # 1️⃣ ID / 身份标识（纯索引）\n",
    "    'permno',      # CRSP 股票唯一标识\n",
    "    'gvkey',       # Compustat 公司唯一标识\n",
    "    # 2️⃣ 时间 / 事件索引（不是特征）\n",
    "    'fyear',       # 财年\n",
    "    'DATE',        # 交易日期\n",
    "    'datadate',    # 会计数据日期\n",
    "    'rdq',         # 财报披露日期\n",
    "    'eamonth',     # 财报月份索引\n",
    "    # 3️⃣ 市场制度 / 状态标签\n",
    "    'exchcd',      # 交易所代码\n",
    "    'IPO',         # IPO 状态标记\n",
    "    # 4️⃣ 原始价格 / 规模 / 交易量（因子“原料”，不是因子）\n",
    "    'prc',         # 股价\n",
    "    'prccq',       # 季度收盘价\n",
    "    'SHROUT',      # 流通股数\n",
    "    'VOL',         # 成交量\n",
    "    'dolvol',      # 成交额\n",
    "    'mve',         # 市值（原始）\n",
    "    'mve_m',       # 月度市值\n",
    "    'pps',         # 每股价格\n",
    "    # 5️⃣ 收益 & 退市相关（被解释变量 / 状态变量）\n",
    "    'RET',         # 股票收益率（因变量）\n",
    "    'dlret',       # 退市收益\n",
    "    'dlstcd',      # 退市代码\n",
    "    # 6️⃣ 回测 / 分组 / 统计产物（严禁当因子）\n",
    "    'count',       # 分组样本数\n",
    "    'ewret',       # 等权组合收益\n",
    "    # 7️⃣ 临时索引 / 垃圾列（必须清理）\n",
    "    'i',           # 中间索引列\n",
    "    'j',    'TRDMNT'       # 中间索引列\n",
    "]\n",
    "\n",
    "\n",
    "# 只保留真正的因子列\n",
    "factor_cols = [\n",
    "    c for c in df_csv_all.columns\n",
    "    if c not in non_factor_cols\n",
    "]\n",
    "\n",
    "print(\"因子列数量:\", len(factor_cols))\n",
    "print(\"前10个因子列:\", factor_cols[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15d08d",
   "metadata": {},
   "source": [
    "# 选取小表\n",
    "任意选取了一个指标,如“RDM”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08de3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 63032 行（1188139 → 1125107）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 7822 行（1188139 → 1180317）\n",
      "firstSort: 删除了 1830 行（1188139 → 1186309）\n",
      "firstSort: 删除了 2701 行（1188139 → 1185438）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 10525 行（1188139 → 1177614）\n",
      "firstSort: 删除了 590609 行（1188139 → 597530）\n",
      "firstSort: 删除了 564223 行（1188139 → 623916）\n",
      "firstSort: 删除了 50110 行（1188139 → 1138029）\n",
      "firstSort: 删除了 50110 行（1188139 → 1138029）\n",
      "firstSort: 删除了 50556 行（1188139 → 1137583）\n",
      "firstSort: 删除了 53723 行（1188139 → 1134416）\n",
      "firstSort: 删除了 90097 行（1188139 → 1098042）\n",
      "firstSort: 删除了 90097 行（1188139 → 1098042）\n",
      "firstSort: 删除了 42246 行（1188139 → 1145893）\n",
      "firstSort: 删除了 90097 行（1188139 → 1098042）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 64888 行（1188139 → 1123251）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 90097 行（1188139 → 1098042）\n",
      "firstSort: 删除了 52153 行（1188139 → 1135986）\n",
      "firstSort: 删除了 77502 行（1188139 → 1110637）\n",
      "firstSort: 删除了 81287 行（1188139 → 1106852）\n",
      "firstSort: 删除了 107211 行（1188139 → 1080928）\n",
      "firstSort: 删除了 361719 行（1188139 → 826420）\n",
      "firstSort: 删除了 101730 行（1188139 → 1086409）\n",
      "firstSort: 删除了 77574 行（1188139 → 1110565）\n",
      "firstSort: 删除了 244937 行（1188139 → 943202）\n",
      "firstSort: 删除了 34689 行（1188139 → 1153450）\n",
      "firstSort: 删除了 86311 行（1188139 → 1101828）\n",
      "firstSort: 删除了 718962 行（1188139 → 469177）\n",
      "firstSort: 删除了 78115 行（1188139 → 1110024）\n",
      "firstSort: 删除了 50101 行（1188139 → 1138038）\n",
      "firstSort: 删除了 81482 行（1188139 → 1106657）\n",
      "firstSort: 删除了 137028 行（1188139 → 1051111）\n",
      "firstSort: 删除了 50077 行（1188139 → 1138062）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 29072 行（1188139 → 1159067）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 16443 行（1188139 → 1171696）\n",
      "firstSort: 删除了 67931 行（1188139 → 1120208）\n",
      "firstSort: 删除了 25084 行（1188139 → 1163055）\n",
      "firstSort: 删除了 77433 行（1188139 → 1110706）\n",
      "firstSort: 删除了 3868 行（1188139 → 1184271）\n",
      "firstSort: 删除了 46132 行（1188139 → 1142007）\n",
      "firstSort: 删除了 331885 行（1188139 → 856254）\n",
      "firstSort: 删除了 374303 行（1188139 → 813836）\n",
      "firstSort: 删除了 21007 行（1188139 → 1167132）\n",
      "firstSort: 删除了 505873 行（1188139 → 682266）\n",
      "firstSort: 删除了 50077 行（1188139 → 1138062）\n",
      "firstSort: 删除了 50077 行（1188139 → 1138062）\n",
      "firstSort: 删除了 888932 行（1188139 → 299207）\n",
      "firstSort: 删除了 897239 行（1188139 → 290900）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 436328 行（1188139 → 751811）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 368624 行（1188139 → 819515）\n",
      "firstSort: 删除了 277059 行（1188139 → 911080）\n",
      "firstSort: 删除了 416688 行（1188139 → 771451）\n",
      "firstSort: 删除了 50077 行（1188139 → 1138062）\n",
      "firstSort: 删除了 683775 行（1188139 → 504364）\n",
      "firstSort: 删除了 50101 行（1188139 → 1138038）\n",
      "firstSort: 删除了 50101 行（1188139 → 1138038）\n",
      "firstSort: 删除了 50077 行（1188139 → 1138062）\n",
      "firstSort: 删除了 81287 行（1188139 → 1106852）\n",
      "firstSort: 删除了 107211 行（1188139 → 1080928）\n",
      "firstSort: 删除了 52153 行（1188139 → 1135986）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 81482 行（1188139 → 1106657）\n",
      "firstSort: 删除了 148395 行（1188139 → 1039744）\n",
      "firstSort: 删除了 42246 行（1188139 → 1145893）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 936317 行（1188139 → 251822）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 319978 行（1188139 → 868161）\n",
      "firstSort: 删除了 15200 行（1188139 → 1172939）\n",
      "firstSort: 删除了 4128 行（1188139 → 1184011）\n",
      "firstSort: 删除了 4135 行（1188139 → 1184004）\n",
      "firstSort: 删除了 5459 行（1188139 → 1182680）\n",
      "firstSort: 删除了 318695 行（1188139 → 869444）\n",
      "firstSort: 删除了 114203 行（1188139 → 1073936）\n",
      "firstSort: 删除了 113979 行（1188139 → 1074160）\n",
      "firstSort: 删除了 318695 行（1188139 → 869444）\n",
      "firstSort: 删除了 3498 行（1188139 → 1184641）\n",
      "firstSort: 删除了 28669 行（1188139 → 1159470）\n",
      "firstSort: 删除了 3013 行（1188139 → 1185126）\n",
      "firstSort: 删除了 5441 行（1188139 → 1182698）\n",
      "firstSort: 删除了 4322 行（1188139 → 1183817）\n",
      "firstSort: 删除了 4208 行（1188139 → 1183931）\n",
      "firstSort: 删除了 3013 行（1188139 → 1185126）\n",
      "firstSort: 删除了 410029 行（1188139 → 778110）\n",
      "firstSort: 删除了 279726 行（1188139 → 908413）\n",
      "firstSort: 删除了 630040 行（1188139 → 558099）\n",
      "firstSort: 删除了 287661 行（1188139 → 900478）\n",
      "firstSort: 删除了 295333 行（1188139 → 892806）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 276716 行（1188139 → 911423）\n",
      "firstSort: 删除了 275258 行（1188139 → 912881）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 6269 行（1188139 → 1181870）\n",
      "firstSort: 删除了 23123 行（1188139 → 1165016）\n",
      "firstSort: 删除了 58282 行（1188139 → 1129857）\n",
      "firstSort: 删除了 188610 行（1188139 → 999529）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 58282 行（1188139 → 1129857）\n",
      "firstSort: 删除了 5815 行（1188139 → 1182324）\n",
      "firstSort: 删除了 23123 行（1188139 → 1165016）\n",
      "firstSort: 删除了 23123 行（1188139 → 1165016）\n",
      "firstSort: 删除了 69 行（1188139 → 1188070）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 16 行（1188139 → 1188123）\n",
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "firstSort: 删除了 275 行（1188139 → 1187864）\n",
      "firstSort: 删除了 7 行（1188139 → 1188132）\n",
      "firstSort: 删除了 77 行（1188139 → 1188062）\n",
      "firstSort: 删除了 70 行（1188139 → 1188069）\n",
      "firstSort: 删除了 9409 行（1188139 → 1178730）\n",
      "firstSort: 删除了 9409 行（1188139 → 1178730）\n",
      "firstSort: 删除了 9409 行（1188139 → 1178730）\n",
      "firstSort: 删除了 9409 行（1188139 → 1178730）\n",
      "firstSort: 删除了 9409 行（1188139 → 1178730）\n",
      "成功分组因子数量: 84\n",
      "失败分组因子数量: 42\n"
     ]
    }
   ],
   "source": [
    "success_factors = []\n",
    "failed_factors = []\n",
    "\n",
    "l = len(factor_cols)\n",
    "\n",
    "for i in range(l):\n",
    "    sort_factor = factor_cols[i]\n",
    "\n",
    "    # 只取必要列\n",
    "    sub_table_test = df_csv_all[['permno', 'TRDMNT', sort_factor, 'RET', 'mve_f']]\n",
    "\n",
    "    # 清洗\n",
    "    df_clean_test = cleanBlank(sub_table_test, 'TRDMNT', 'permno')\n",
    "\n",
    "    try:\n",
    "        sub_table_groupped_test = GroupN(\n",
    "            df_clean_test,\n",
    "            sort_var='TRDMNT',\n",
    "            vars=sort_factor,\n",
    "            n_group=ngroup\n",
    "        )\n",
    "        success_factors.append(sort_factor)\n",
    "\n",
    "    except Exception as e:\n",
    "        failed_factors.append({\n",
    "            \"factor\": sort_factor,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        continue\n",
    "\n",
    "print(\"成功分组因子数量:\", len(success_factors))\n",
    "print(\"失败分组因子数量:\", len(failed_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_factor = success_factors[0]\n",
    "sub_table = df_csv_all[['permno','TRDMNT',sort_factor,'RET','mve_f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73db28af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstSort: 删除了 0 行（1188139 → 1188139）\n",
      "     permno  TRDMNT        bm       RET       mve_f\n",
      "0     10001  200001  0.644588 -0.044118   20.993250\n",
      "207   10002  200001  0.509429 -0.025641  115.710000\n",
      "365   10009  200001  0.757597 -0.008475   50.610000\n",
      "376   10012  200001  0.130151 -0.097276   34.628937\n",
      "444   10016  200001  0.183991 -0.099338  300.372813\n"
     ]
    }
   ],
   "source": [
    "df_clean=cleanBlank(sub_table, 'TRDMNT','permno')\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fc732a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "#                   第一步、分组\n",
    "#========================================================\n",
    "\n",
    "def GroupN(in_df, sort_var, vars, n_group=10):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[f\"{vars}_g{n_group}\"] = out_df.groupby(sort_var)[vars].transform(\n",
    "        lambda x: pd.qcut(x, q=n_group, labels=[i for i in range(1, n_group+1)]))\n",
    "    out_df[f\"{vars}_g{n_group}\"] = out_df[f\"{vars}_g{n_group}\"] .astype(int)\n",
    "    return out_df\n",
    "\n",
    "\n",
    "sub_table_groupped = GroupN(df_clean, 'TRDMNT', sort_factor, n_group = ngroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b93f8f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "#                   第二步、缩尾处理\n",
    "#          对除了keep_cols以外的所有因子进行缩尾处理\n",
    "#========================================================\n",
    "\n",
    "class Winsorize:\n",
    "    def __init__(self, in_df, sort_var, vars, perc=1, trim=0) -> None:\n",
    "        self.in_df = in_df\n",
    "        self.sort_var = sort_var\n",
    "        self.vars = vars\n",
    "        self.perc = perc\n",
    "        self.trim = trim\n",
    "\n",
    "    def func_trim(self, in_ser, perc):\n",
    "        perc_upper = (100 - perc) / 100\n",
    "        perc_lower = perc / 100\n",
    "\n",
    "        qt_lower, qt_upper = in_ser.quantile([perc_lower, perc_upper])\n",
    "        in_ser[in_ser > qt_upper] = np.nan\n",
    "        in_ser[in_ser < qt_lower] = np.nan\n",
    "        return in_ser\n",
    "\n",
    "    def func_winsor(self, in_ser, perc):\n",
    "        perc_upper = (100 - perc) / 100\n",
    "        perc_lower = perc / 100\n",
    "        qt_lower, qt_upper = in_ser.quantile([perc_lower, perc_upper])\n",
    "\n",
    "        in_ser[in_ser > qt_upper] = qt_upper\n",
    "        in_ser[in_ser < qt_lower] = qt_lower\n",
    "        return in_ser\n",
    "\n",
    "    def get(self, ):\n",
    "        out_df = self.in_df.copy()\n",
    "        if self.trim == 1:\n",
    "            proc_method = self.func_trim\n",
    "        if self.trim == 0:\n",
    "            proc_method = self.func_winsor\n",
    "\n",
    "        out_df[f\"{self.vars}\"] = out_df.groupby(\n",
    "            self.sort_var)[self.vars].transform(lambda x: proc_method(x, 1))\n",
    "\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ff51ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winsorize\n",
    "#先对size进行缩尾处理\n",
    "winsor = Winsorize(sub_table_groupped, \"TRDMNT\",'mve_f')\n",
    "sub_table_groupped = winsor.get()\n",
    "# 第二次缩尾：按（月 × 因子组）对 size 缩尾\n",
    "winsor = Winsorize(sub_table_groupped, [\"TRDMNT\",f\"{sort_factor}_g{ngroup}\" ],'mve_f')\n",
    "sub_table_groupped = winsor.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e232f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     permno  TRDMNT        bm       RET       mve_f  bm_g10\n",
      "0     10001  200001  0.644588 -0.044118   20.993250       7\n",
      "207   10002  200001  0.509429 -0.025641  115.710000       5\n",
      "365   10009  200001  0.757597 -0.008475   50.610000       7\n",
      "376   10012  200001  0.130151 -0.097276   34.628937       2\n",
      "444   10016  200001  0.183991 -0.099338  300.372813       2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#========================================================\n",
    "#                   第三步、计算EW VW\n",
    "#           EW=同一个月 (TRDMNT)\n",
    "#           同一个因子分组（比如 AM_g10 的第 3 组）\n",
    "#           把这一组里所有股票的收益率 ret 简单平均。\n",
    "#           VW=同一个月\n",
    "#           同一个因子组\n",
    "#           用上一期市值 size 当权重，对收益率加权平均\n",
    "#\n",
    "#       在这里的收益率指的是RET [考虑现金红利再投资的月个股回报率]\n",
    "#       从这里开始就只有一个了，上面都是对全部的因子进行循环处理\n",
    "#=======================================================\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def get_stat(ret_df, max_lag: int = None):\n",
    "\n",
    "    inner_df = ret_df.copy()\n",
    "\n",
    "    ret_mean = inner_df.mean() * 100\n",
    "\n",
    "    if max_lag == None:\n",
    "        ret_t = stats.ttest_1samp(inner_df, 0)[0]\n",
    "        ret_p = stats.ttest_1samp(inner_df, 0)[1]\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    else:\n",
    "        assert type(max_lag) == int, \"input an integer max_lag\"\n",
    "        ret_t = []\n",
    "        ret_p = []\n",
    "        for col in inner_df.columns:\n",
    "            reg = smf.ols(f\"{col} ~ 1\", data=inner_df).fit(\n",
    "                cov_type='HAC', cov_kwds={'maxlags': max_lag})\n",
    "            t_v = reg.tvalues['Intercept']\n",
    "            p_v = reg.pvalues['Intercept']\n",
    "            ret_t.append(t_v)\n",
    "            ret_p.append(p_v)\n",
    "        ret_t = pd.Series(ret_t, index=ret_mean.index)\n",
    "        ret_p = pd.Series(ret_p, index=ret_mean.index)\n",
    "    \n",
    "    ret_mean.name = 'mean'\n",
    "    ret_t.name = 't'\n",
    "    ret_p.name = 'p'\n",
    "    \n",
    "    stats_data = pd.DataFrame([ret_mean, ret_t, ret_p])\n",
    "    return stats_data\n",
    "\n",
    "in_ret = sub_table_groupped.copy(deep =True)\n",
    "print(in_ret.head(5))\n",
    "\n",
    "ew_ret = in_ret.groupby(['TRDMNT', f\"{sort_factor}_g{ngroup}\"])['RET'].mean()\n",
    "vw_ret = (\n",
    "    in_ret.groupby(['TRDMNT', f\"{sort_factor}_g{ngroup}\"])\n",
    "          .apply(lambda g: np.average(g['RET'], weights=g['mve_f']))\n",
    ")\n",
    "vw_ret.name = \"Vw_ret\"\n",
    "\n",
    "ew_mean = ew_ret.copy(deep=True)\n",
    "ew_mean.name = 'Ew_ret'\n",
    "\n",
    "vw_mean = vw_ret.copy(deep=True)\n",
    "vw_mean.name = 'Vw_ret'\n",
    "\n",
    "month_count = in_ret.groupby(\n",
    "    ['TRDMNT', f\"{sort_factor}_g{ngroup}\"]\n",
    ")['RET'].count()\n",
    "month_count.name = 'Count'\n",
    "\n",
    "sort_factor_mean = in_ret.groupby(\n",
    "    ['TRDMNT', f\"{sort_factor}_g{ngroup}\"]\n",
    ")[sort_factor].mean()\n",
    "\n",
    "month_result = pd.concat(\n",
    "    [month_count, sort_factor_mean, ew_mean, vw_mean],\n",
    "    axis=1,\n",
    "    ignore_index=False\n",
    ")\n",
    "\n",
    "ew_ret = ew_ret.unstack()\n",
    "vw_ret = vw_ret.unstack()\n",
    "\n",
    "ew_ret.columns = [f\"col_{i+1}\" for i in range(ngroup)]\n",
    "vw_ret.columns = [f\"col_{i+1}\" for i in range(ngroup)]\n",
    "\n",
    "ew_ret['high_low'] = ew_ret[f\"col_{ngroup}\"] - ew_ret[\"col_1\"]\n",
    "vw_ret['high_low'] = vw_ret[f\"col_{ngroup}\"] - vw_ret[\"col_1\"]\n",
    "\n",
    "ew_other = ew_ret.loc[:, ['high_low']]\n",
    "ew_other = ew_other.stack()\n",
    "ew_other.name = 'Ew_ret'\n",
    "\n",
    "vw_other = vw_ret.loc[:, ['high_low']]\n",
    "vw_other = vw_other.stack()\n",
    "vw_other.name = 'Vw_ret'\n",
    "\n",
    "other = pd.concat([ew_other, vw_other], axis=1, ignore_index=False)\n",
    "other = other.reset_index()\n",
    "other = other.rename(columns={'level_1': f\"{sort_factor}_g{ngroup}\"})\n",
    "other = other.set_index(['TRDMNT', f\"{sort_factor}_g{ngroup}\"])\n",
    "\n",
    "month_result = pd.concat([month_result, other], axis=0, ignore_index=False)\n",
    "month_result.sort_index(inplace=True)\n",
    "\n",
    "month_result.to_csv(os.path.join(op_path, f\"{sort_factor}_month_result.csv\"))\n",
    "\n",
    "# 如果 index 是 PeriodIndex，用 to_timestamp\n",
    "if isinstance(ew_ret.index, pd.PeriodIndex):\n",
    "    ew_ret.index = ew_ret.index.to_timestamp(how=\"end\")\n",
    "\n",
    "if isinstance(vw_ret.index, pd.PeriodIndex):\n",
    "    vw_ret.index = vw_ret.index.to_timestamp(how=\"end\")\n",
    "\n",
    "ew_stat = get_stat(ew_ret, max_lag = 3)\n",
    "vw_stat = get_stat(vw_ret, max_lag = 3)\n",
    "\n",
    "ew_stat.to_csv(os.path.join(op_path, f\"{sort_factor}_ew_result.csv\"))\n",
    "vw_stat.to_csv(os.path.join(op_path, f\"{sort_factor}_vw_result.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
